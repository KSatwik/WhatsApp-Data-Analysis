# -*- coding: utf-8 -*-
"""Satwik_whatsapp_data_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QzOkEGdCs2FIxRq7xzKa0s5909sCnGyr
"""

# Install required libraries
!pip install emoji

from google.colab import drive
drive.mount('/content/drive')

# read text from file 
file_location = './drive/MyDrive/WhatsApp Chat with "Ohhhhkkkk Unofficial"ðŸ˜ŽðŸ˜Ž.txt'
with open(file_location) as f:
  data = f.read()
  data = ' '.join(data.split('\n'))

#separate user messages and datetime of the chat
import re
pattern = '\d{1,2}/\d{1,2}/\d{2,4},\s\d{1,2}:\d{2}\s-\s'
user_messages = re.split(pattern, data)[1:]
message_dates =  re.findall(pattern, data)
print(data)
print(user_messages)
# print(message_dates)
# load user messages and dates into dataframe
import pandas as pd
df = pd.DataFrame({'user_message':user_messages, 'message_date': message_dates})
# convert message_date type
df['message_date'] = pd.to_datetime(df['message_date'], format='%d/%m/%Y, %H:%M - ')

df.rename(columns={'message_date': 'date'}, inplace=True)

# separate users and messages 
users = []
messages = []
for message in df['user_message']:
  entry = re.split('([\w\W]+?):\s', message)
  if entry[1:]:# user name
    users.append(entry[1])
    messages.append(entry[2])
  else:
    users.append('group_notification')
    messages.append(entry[0])

df['user'] =  users
df['message'] = messages
df.drop(columns=['user_message'], inplace=True)

print(df.tail())

# data cleaning 
# 1. remove all the <Media omitted> messages
images = df[df['message'] == '<Media omitted> ']
print("Total number of Images + Videos Shared: ", len(images))
df.drop(images.index, inplace=True)
# 2. remove all group notifications
notifications = df[df['user'] == 'group_notification']
print("Total Group Notifications: ", len(notifications))
df.drop(notifications.index, inplace=True)

# reset the index 
df.reset_index(inplace=True, drop=True)
df.tail()

"""# 1. Who is most active in the group """

df.groupby('user')['message'].count().sort_values(ascending=False)

"""# 2. Frequently used emojis in the group"""

import emoji
from collections import Counter
# Count all the emojis in the chat.
emoji_counter = Counter()
emojis_list = map(lambda x: ''.join(x.split()), emoji.UNICODE_EMOJI['en'].keys())
r = re.compile('|'.join(re.escape(p) for p in emojis_list))
for index, row in df.iterrows():
  emojis_found = r.findall(row['message'])
  for emoji_f in emojis_found:
    emoji_counter[emoji_f] +=1

for item in emoji_counter.most_common(10):
  print(f'{item[0]} - {item[1]}')

"""# 3. Sleep Cycles of the group"""

#3 sleep cycle 
df['hour'] = df['date'].apply(lambda x: x.hour)
df.groupby(['hour']).size().sort_index().plot(x="hour", kind='bar')

"""# 4. Word Cloud"""

from wordcloud import WordCloud, STOPWORDS
all_words = ' '
stopwords = STOPWORDS.update(['re', 'mam', 'python', 'yes', 'no', 'how', 'sem', 'mids', 'lab', 'external', 'satwik', 'hi', 'bye', 'ok', 'will'])
for msg in df['message'].values:
  words = str(msg).lower().split()
  for word in words:
    all_words = all_words + word + ' '

wordcloud = WordCloud(width = 1000, height = 800, 
                background_color ='white', 
                stopwords = stopwords, 
                min_font_size = 10).generate(all_words) 


wordcloud.to_image()

